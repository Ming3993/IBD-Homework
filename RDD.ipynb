{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epfrvqOy0XbK"
      },
      "source": [
        "# Install Java and Spark on Hadoop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf3zOXQkRf0l",
        "outputId": "a40a8622-eee3-452a-842d-724976cf9dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,690 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,833 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [34.3 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,099 kB]\n",
            "Fetched 20.5 MB in 3s (7,929 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "# install java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# install spark (change the version number if needed)\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz\n",
        "# unzip the spark file to the current folder\n",
        "!tar xf spark-3.5.5-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Llc1FhGNQ3U5"
      },
      "outputs": [],
      "source": [
        "# set your spark folder to your system path environment.\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.5-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfAmwnpt1G5p"
      },
      "source": [
        "# Create a SparkSession in Python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import size"
      ],
      "metadata": {
        "id": "vgslf5hgxRpM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ExFt_N8-z2m",
        "outputId": "6d252f14-62da-4ef1-a297-e48102b31bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: findspark in /usr/local/lib/python3.11/dist-packages (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "# start pyspark\n",
        "!pip install findspark\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZU-oJLNVQl45"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local\")\\\n",
        "          .appName(\"Spark APIs Exercises\")\\\n",
        "          .config(\"spark.some.config.option\", \"some-value\")\\\n",
        "          .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chdGpJrATCDO"
      },
      "source": [
        "# Example 1: WordCount with Spark DataFrames and Spark RDDs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91A6eRPJUl_0",
        "outputId": "950b8b4a-1a51-440f-f928-3cf2cf678b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CSC14118'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 17 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (17/17), 818.44 KiB | 4.20 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "!git clone https://github.com/nnthaofit/CSC14118.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJj_K5siTgAx"
      },
      "source": [
        "### Spark DataFrame-based WordCount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NACaHF44TG_L",
        "outputId": "94b746b2-d4bf-426f-bf44-f0c7a59bdb6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------+\n",
            "|value                       |\n",
            "+----------------------------+\n",
            "|ppap                        |\n",
            "|i have a pen                |\n",
            "|i have an apple             |\n",
            "|ah apple pen                |\n",
            "|i have a pen                |\n",
            "|i have a pineapple          |\n",
            "|ah pineapple pen            |\n",
            "|ppap pen pineapple apple pen|\n",
            "+----------------------------+\n",
            "\n",
            "+---------+-----+\n",
            "|     word|count|\n",
            "+---------+-----+\n",
            "|      pen|    6|\n",
            "|     have|    4|\n",
            "|        i|    4|\n",
            "|    apple|    3|\n",
            "|pineapple|    3|\n",
            "|        a|    3|\n",
            "|     ppap|    2|\n",
            "|       ah|    2|\n",
            "|       an|    1|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "linesDF = spark.read.text(\"CSC14118/ppap.txt\")\n",
        "linesDF.show(linesDF.count(),truncate = False)\n",
        "\n",
        "from pyspark.sql import functions as f\n",
        "wordsDF = linesDF.withColumn(\"word\", f.explode(f.split(f.col(\"value\"), \" \")))\\\n",
        "    .groupBy(\"word\")\\\n",
        "    .count()\\\n",
        "    .sort(\"count\", ascending = False)\n",
        "wordsDF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82hKvCdcTj6g"
      },
      "source": [
        "###RDD-based WordCount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONOtAnLxSxYK",
        "outputId": "95102a82-c8da-4799-db48-85d5553a004f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('pen', 6),\n",
              " ('i', 4),\n",
              " ('have', 4),\n",
              " ('a', 3),\n",
              " ('apple', 3),\n",
              " ('pineapple', 3),\n",
              " ('ppap', 2),\n",
              " ('ah', 2),\n",
              " ('an', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "linesRdd = spark.sparkContext.textFile(\"CSC14118/ppap.txt\")\n",
        "wordsRdd = linesRdd.flatMap(lambda line: line.split(\" \")) \\\n",
        "    .map(lambda word: (word, 1)) \\\n",
        "    .reduceByKey(lambda a, b: a + b)\\\n",
        "    .sortBy(lambda pair:-1*pair[1])\n",
        "wordsRdd.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1: Data query with Spark DataFrame"
      ],
      "metadata": {
        "id": "eskNBM_J66UP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the example data files from GitHub to Drive\n",
        "!git clone https://github.com/nnthaofit/CSC14118.git"
      ],
      "metadata": {
        "id": "T5YNLLU6656Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d817f0b8-1db1-4ca2-c4a8-23ca7f3d542e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CSC14118' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###0. Load the data file: movies.json"
      ],
      "metadata": {
        "id": "EbUxY_c-69xG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"json\").load(\"/content/CSC14118/movies.json\")"
      ],
      "metadata": {
        "id": "ZMLl4NC4t6_-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1a. Show the schema of DataFrame that stores the movies dataset."
      ],
      "metadata": {
        "id": "HNfJKss_7cG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "rJhoYcqQt8XV",
        "outputId": "b1677ec1-e289-46a9-e421-dc95df477b2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- cast: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- genres: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- year: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1b. Show the number of distinct movies in the dataset"
      ],
      "metadata": {
        "id": "alyy1VZT7rve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.distinct().count()"
      ],
      "metadata": {
        "id": "u6Irt5YPt955",
        "outputId": "e519fa8c-84ff-4e64-f59f-2f9bdf6f141c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28789"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Count the number of movies released during the years 2012 and 2015 (included)"
      ],
      "metadata": {
        "id": "lbRNx-QU73ZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.distinct().where((2012 <= df.year) & (df.year <= 2015)).count()"
      ],
      "metadata": {
        "id": "AQFTKSdYt_9G",
        "outputId": "d730c0fd-1338-4adf-fdca-9de68901207b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1015"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Show the year in which the number of movies released is highest. One highest year is enough"
      ],
      "metadata": {
        "id": "Wm7NfqXp76Cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.distinct().select(\"year\").sort(\"year\", ascending=False).show(1)"
      ],
      "metadata": {
        "id": "H6fj91IzuBcO",
        "outputId": "ff1b5b6d-76be-4119-b53e-05dc6743471c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+\n",
            "|year|\n",
            "+----+\n",
            "|2018|\n",
            "+----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Show the list of movies such that for each film, the number of actors/actresses is at least five, and the number of genres it belongs to is at most two genres."
      ],
      "metadata": {
        "id": "EpfIvw-h8Eep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = df.filter(\n",
        "    (size(\"cast\") >= 5) & (size(\"genres\") <= 2)\n",
        ")\n",
        "\n",
        "filtered_df.select(\"title\", \"cast\", \"genres\").show(truncate=False)"
      ],
      "metadata": {
        "id": "_TD58zTjuEzm",
        "outputId": "3235ea7c-14df-4c35-9ae1-f83b21d69763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+\n",
            "|title                           |cast                                                                                                                                                                          |genres          |\n",
            "+--------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+\n",
            "|A Desperate Chance              |[Earle Foxe, Alie Hollister, Robert G. Vignola, Helen Lidroth, Miriam Cooper]                                                                                                 |[Drama]         |\n",
            "|The Archeologist                |[Charlotte Burton, Edward Coxen, George Field, Winifred Greenwood, John Steppling]                                                                                            |[Drama]         |\n",
            "|At the Potter's Wheel           |[Charlotte Burton, Sydney Ayres, Caroline Frances Cooke, Louise Lester, Jack Richardson, Vivian Rich]                                                                         |[Drama]         |\n",
            "|Back to the Farm                |[Herbert Tracey, Royal Byron, Eloise Willard, Mabel Paige, Oliver Hardy]                                                                                                      |[Comedy]        |\n",
            "|The Beggar Child                |[Charlotte Burton, Edward Coxen, George Field, Winifred Greenwood, John Steppling]                                                                                            |[]              |\n",
            "|Billy's Rival                   |[William Garwood, Louise Lester, Jack Richardson, Vivian Rich, ., Harry von Meter]                                                                                            |[]              |\n",
            "|Break, Break, Break             |[B. Reeves Eason, William Garwood, Louise Lester, Jack Richardson, Vivian Rich, Harry von Meter]                                                                              |[Drama]         |\n",
            "|The Butterfly                   |[Charlotte Burton, George Field, Edward Coxen, Edith Borella, Jean Durrell, Ida Lewis, John Steppling]                                                                        |[]              |\n",
            "|Calamity Anne's Love Affair     |[Charlotte Burton, Louise Lester, George Field, Edith Borella, B. Reeves Eason]                                                                                               |[Western]       |\n",
            "|The Star Boarder                |[Charlie Chaplin, Minta Durfee, Edgar Kennedy, Alice Davenport, Gordon Griffith]                                                                                              |[Comedy]        |\n",
            "|A Story of Little Italy         |[Sydney Ayres, Jacques Jaccard, Jack Richardson, Vivian Rich, Harry von Meter]                                                                                                |[]              |\n",
            "|The Story of the Olive          |[Sydney Ayres, Perry Banks, Edith Borella, Caroline Cooke, Harry von Meter]                                                                                                   |[]              |\n",
            "|This Is th' Life                |[Charlotte Burton, George Field, Edward Coxen, Edith Borella, John Steppling]                                                                                                 |[]              |\n",
            "|The Ace of Hearts               |[Lon Chaney, Leatrice Joy, John Bowers, Hardee Kirkland, Raymond Hatton]                                                                                                      |[Crime, Drama]  |\n",
            "|The Purple Highway              |[Madge Kennedy, Monte Blue, Vincent Coleman, and, Pedro de Córdoba]                                                                                                           |[Comedy, Drama] |\n",
            "|The Thief of Bagdad             |[Douglas Fairbanks, Snitz Edwards, Charles Belcher, Julanne Johnston, Anna May Wong]                                                                                          |[]              |\n",
            "|Chang: A Drama of the Wilderness|[Kru, Chantui, Nah, Ladah, Bimbo]                                                                                                                                             |[Documentary]   |\n",
            "|Sorrell and Son                 |[H. B. Warner, Anna Q. Nilsson, Louis Wolheim, Alice Joyce, Nils Asther, Mary Nolan]                                                                                          |[Drama]         |\n",
            "|The Wreck of the Hesperus       |[Sam De Grasse, Virginia Bradford, Francis Ford, Francis Marion, Alan Hale, Ethel Wales]                                                                                      |[Adventure]     |\n",
            "|Anthony Adverse                 |[Fredric March, Olivia de Havilland, Donald Woods, Anita Louise, Edmund Gwenn, Claude Rains, Louis Hayward, Gale Sondergaard, (, Academy Award for Best Supporting Actress, )]|[Drama, Romance]|\n",
            "+--------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Show the **movies** whose names are longest"
      ],
      "metadata": {
        "id": "TG1zzyVb8ND9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import length, max as spark_max\n",
        "\n",
        "# Tính độ dài tên phim\n",
        "df_with_length = df.withColumn(\"title_length\", length(\"title\"))\n",
        "\n",
        "# Tìm độ dài lớn nhất\n",
        "max_length = df_with_length.agg(spark_max(\"title_length\")).collect()[0][0]\n",
        "\n",
        "# Lọc ra các phim có độ dài tên bằng max_length\n",
        "longest_title_movies = df_with_length.filter(df_with_length[\"title_length\"] == max_length)\n",
        "\n",
        "# Hiển thị\n",
        "longest_title_movies.select(\"title\").show(truncate=False)"
      ],
      "metadata": {
        "id": "YsBt1ARluGJJ",
        "outputId": "9fdb0c4e-4470-44b1-913d-b8d7cf6cdaf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "|title                                                                                                         |\n",
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "|Cornell-Columbia-University of Pennsylvania Boat Race at Ithaca, N.Y., Showing Lehigh Valley Observation Train|\n",
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Show the movies whose name contains the word “fighting” (case-insensitive)."
      ],
      "metadata": {
        "id": "h-UJvT_I8QHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lower\n",
        "\n",
        "filtered_df = df.filter(lower(df.title).contains(\"fighting\"))\n",
        "filtered_df.select(\"title\").show(truncate=False)"
      ],
      "metadata": {
        "id": "fvTK-g-AuHnu",
        "outputId": "c5bd027a-4e93-408d-dd17-a7c44a477bf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+\n",
            "|title                  |\n",
            "+-----------------------+\n",
            "|A Fighting Colleen     |\n",
            "|Fighting Cressy        |\n",
            "|Fighting Destiny       |\n",
            "|Fighting for Gold      |\n",
            "|The Fighting Heart     |\n",
            "|The Fighting Line      |\n",
            "|The Fighting Guide     |\n",
            "|The Fighting Streak    |\n",
            "|The Fighting Blade     |\n",
            "|The Fighting Coward    |\n",
            "|Fighting Fury          |\n",
            "|The Fighting Adventurer|\n",
            "|The Fighting Sap       |\n",
            "|The Fighting Demon     |\n",
            "|Fighting Fate          |\n",
            "|The Fighting Heart     |\n",
            "|Fighting Luck          |\n",
            "|The Fighting Smile     |\n",
            "|Fighting the Flames    |\n",
            "|Fighting Youth         |\n",
            "+-----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Show the list of distinct genres appearing in the dataset"
      ],
      "metadata": {
        "id": "sZwOdpkG8Wkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "\n",
        "distinct_genres = df.select(explode(\"genres\").alias(\"genre\")).distinct()\n",
        "distinct_genres.show(truncate=False)"
      ],
      "metadata": {
        "id": "e2Bkyz_DuI3-",
        "outputId": "802d4f6b-bd93-4b9c-b3e4-92845c74c5f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|genre        |\n",
            "+-------------+\n",
            "|Crime        |\n",
            "|Romance      |\n",
            "|Thriller     |\n",
            "|Slasher      |\n",
            "|Found Footage|\n",
            "|Adventure    |\n",
            "|Teen         |\n",
            "|Martial Arts |\n",
            "|Sports       |\n",
            "|Drama        |\n",
            "|War          |\n",
            "|Documentary  |\n",
            "|Family       |\n",
            "|Fantasy      |\n",
            "|Silent       |\n",
            "|Disaster     |\n",
            "|Legal        |\n",
            "|Mystery      |\n",
            "|Supernatural |\n",
            "|Suspense     |\n",
            "+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. List all movies in which the actor Harrison Ford has participated."
      ],
      "metadata": {
        "id": "zIS1IRFP8ZVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import array_contains\n",
        "\n",
        "# harrison_ford_movies = df.filter(array_contains(df.cast, \"Harrison Ford\"))\n",
        "# harrison_ford_movies.select(\"title\").show(truncate=False)\n",
        "\n",
        "df.withColumn(\"actor\", explode(df[\"cast\"])).where(lower(col(\"actor\")) == \"harrison ford\").select(df.columns).show()"
      ],
      "metadata": {
        "id": "Ooe3eFjDuJ8q",
        "outputId": "da897961-daf7-4317-8017-43741b905dad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------------+--------------------+----+\n",
            "|                cast|           genres|               title|year|\n",
            "+--------------------+-----------------+--------------------+----+\n",
            "|[Constance Talmad...|[Romance, Comedy]|Experimental Marr...|1919|\n",
            "|[Constance Talmad...|         [Comedy]| Happiness a la Mode|1919|\n",
            "|[Constance Talmad...|         [Comedy]|Romance and Arabella|1919|\n",
            "|[Vivian Martin, H...|         [Comedy]|      The Third Kiss|1919|\n",
            "|[Harrison Ford, C...|         [Comedy]|The Veiled Adventure|1919|\n",
            "|[Constance Talmad...|         [Comedy]|          Who Cares?|1919|\n",
            "|[Vivian Martin, H...|          [Drama]|You Never Saw Suc...|1919|\n",
            "|[Norma Talmadge, ...|          [Drama]| The Wonderful Thing|1921|\n",
            "|[Alma Rubens, Har...|        [Mystery]|      Find the Woman|1922|\n",
            "|[Constance Talmad...|          [Drama]| The Primitive Lover|1922|\n",
            "|[Norma Talmadge, ...| [Romance, Drama]|     Smilin' Through|1922|\n",
            "|[Helen Jerome Edd...|          [Drama]|     When Love Comes|1922|\n",
            "|[Marion Davies, H...|     [Historical]| Little Old New York|1923|\n",
            "|[Madge Kennedy, H...|          [Drama]|     Three Miles Out|1924|\n",
            "|[Margaret Livings...|          [Drama]|           The Wheel|1925|\n",
            "|[Marie Prevost, H...|         [Comedy]|       Almost a Lady|1926|\n",
            "|[Harrison Ford, M...|          [Drama]| Hell's Four Hundred|1926|\n",
            "|[Harrison Ford, P...|         [Comedy]|   The Nervous Wreck|1926|\n",
            "|[Marie Prevost, H...|         [Comedy]|  Up in Mabel's Room|1926|\n",
            "|[Vera Reynolds, H...|         [Comedy]|         Golf Widows|1928|\n",
            "+--------------------+-----------------+--------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. List all movies in which the actors/actresses whose names include the word “Lewis“ (case-insensitive) have participated."
      ],
      "metadata": {
        "id": "Gj6gxLvh8cXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode, lower, col\n",
        "\n",
        "# Tách từng diễn viên ra dòng riêng, rồi lọc\n",
        "lewis_cast_df = df.select(\"title\", explode(\"cast\").alias(\"actor\"))\n",
        "lewis_movies = lewis_cast_df.filter(lower(col(\"actor\")).contains(\"lewis\"))\n",
        "\n",
        "# Lấy danh sách phim duy nhất\n",
        "lewis_movies.select(\"title\").distinct().show(truncate=False)\n"
      ],
      "metadata": {
        "id": "GW8U4Yv1uLGC",
        "outputId": "8720b85f-22d5-4533-fb4d-b65d4beae3b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------+\n",
            "|title                      |\n",
            "+---------------------------+\n",
            "|Inez from Hollywood        |\n",
            "|The Ballad of Jack and Rose|\n",
            "|Salvage                    |\n",
            "|At War with the Army       |\n",
            "|Sex and the City 2         |\n",
            "|Diary of a Madman          |\n",
            "|Going Straight             |\n",
            "|Cinderfella                |\n",
            "|Gangs of New York          |\n",
            "|That's My Boy              |\n",
            "|Rock-A-Bye Baby            |\n",
            "|The Crucible               |\n",
            "|The Million Dollar Handicap|\n",
            "|The Girl from Montmartre   |\n",
            "|Romance                    |\n",
            "|New Morals for Old         |\n",
            "|The Hardys Ride High       |\n",
            "|Andy Hardy Meets Debutante |\n",
            "|Love Laughs at Andy Hardy  |\n",
            "|Cheaper to Marry           |\n",
            "+---------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Show top five actors/actresses that have participated in most movies."
      ],
      "metadata": {
        "id": "s_EhHiV38fXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode, col\n",
        "\n",
        "top_actors = (\n",
        "    df.select(explode(\"cast\").alias(\"actor\"))\n",
        "      .groupBy(\"actor\")\n",
        "      .count()\n",
        "      .orderBy(col(\"count\").desc())\n",
        "      .limit(5)\n",
        ")\n",
        "\n",
        "top_actors.show(truncate=False)"
      ],
      "metadata": {
        "id": "8iHf9EAluOMC",
        "outputId": "28447da5-1594-4f8a-8ad0-c30d369589e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-----+\n",
            "|actor           |count|\n",
            "+----------------+-----+\n",
            "|Harold Lloyd    |190  |\n",
            "|Hoot Gibson     |142  |\n",
            "|John Wayne      |136  |\n",
            "|Charles Starrett|116  |\n",
            "|Bebe Daniels    |103  |\n",
            "+----------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 2: RDD-based mainpulation\n",
        "\n",
        "\n",
        "*   The data is already in one ore more RDDs.\n",
        "*   You must not convert RDD to DF or use pure Python code.\n"
      ],
      "metadata": {
        "id": "aHQb93lRHj3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Consider a string s that includes only alphabetical letters and spaces. Check whether s is a palindrome (case-insensitive)."
      ],
      "metadata": {
        "id": "o1F4O-msHoDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"U i a i u\"\n",
        "rdd = spark.sparkContext.parallelize(s.lower(),1)\n",
        "rdd.collect()"
      ],
      "metadata": {
        "id": "sTSEfW6WuQ_e",
        "outputId": "cf6410a2-b827-4930-a3ad-83e83ac848d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['u', ' ', 'i', ' ', 'a', ' ', 'i', ' ', 'u']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_id = spark.sparkContext.parallelize(range(0, rdd.count()), 1)\n",
        "rdd_id.collect()"
      ],
      "metadata": {
        "id": "mgDdvbUn7gBb",
        "outputId": "dbf544d8-6274-4f63-fb78-17f088f710d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_a = rdd_id.zip(rdd)\n",
        "rdd_a.collect()"
      ],
      "metadata": {
        "id": "KDP5FnWV7_U9",
        "outputId": "f1525308-6c43-4e32-d6f7-5827008d6c20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 'u'),\n",
              " (1, ' '),\n",
              " (2, 'i'),\n",
              " (3, ' '),\n",
              " (4, 'a'),\n",
              " (5, ' '),\n",
              " (6, 'i'),\n",
              " (7, ' '),\n",
              " (8, 'u')]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_b = rdd_a.sortBy(lambda x: x[0], ascending=False)\n",
        "rdd_b.collect()"
      ],
      "metadata": {
        "id": "kWyaOBiw8OU6",
        "outputId": "6fabcd59-292f-4688-91d2-a66d730d4528",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(8, 'u'),\n",
              " (7, ' '),\n",
              " (6, 'i'),\n",
              " (5, ' '),\n",
              " (4, 'a'),\n",
              " (3, ' '),\n",
              " (2, 'i'),\n",
              " (1, ' '),\n",
              " (0, 'u')]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_compare = rdd_a.zip(rdd_b)\n",
        "rdd_compare.collect()"
      ],
      "metadata": {
        "id": "aPKDwXxX8cmr",
        "outputId": "e56c7c45-3bf6-4b52-a407-685cdd219b8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((0, 'u'), (8, 'u')),\n",
              " ((1, ' '), (7, ' ')),\n",
              " ((2, 'i'), (6, 'i')),\n",
              " ((3, ' '), (5, ' ')),\n",
              " ((4, 'a'), (4, 'a')),\n",
              " ((5, ' '), (3, ' ')),\n",
              " ((6, 'i'), (2, 'i')),\n",
              " ((7, ' '), (1, ' ')),\n",
              " ((8, 'u'), (0, 'u'))]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (rdd_compare.filter(lambda row: row[0][1] != row[1][1]).count() == 0):\n",
        "  print(\"Palindrome\")\n",
        "else:\n",
        "  print(\"Not Palindrome\")"
      ],
      "metadata": {
        "id": "6K8Xu_BP8s5w",
        "outputId": "04343bf8-e498-4cb6-a8ec-5e572ffc775f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palindrome\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Consider a string s that includes only alphabetical letters and spaces. Check whether s is a pangram (case-insensitive)."
      ],
      "metadata": {
        "id": "J6QVU6UWHwYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Nhat Minh\"\n",
        "rdd_str = spark.sparkContext.parallelize(s.replace(\" \",\"\").lower(),1)\n",
        "rdd_str.collect()"
      ],
      "metadata": {
        "id": "qTm-tBGh-SkH",
        "outputId": "5480af0d-c11b-4d1d-a662-5aa2cb67bbd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['n', 'h', 'a', 't', 'm', 'i', 'n', 'h']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_str = rdd_str.sortBy(lambda x: x[0], ascending=False)\n",
        "rdd_str.collect()"
      ],
      "metadata": {
        "id": "If1Kbxdg-sF-",
        "outputId": "a09982c6-cf50-4935-b985-75bd0e371382",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (rdd_str.distinct().count() == 26):\n",
        "  print(\"Pangram\")\n",
        "else:\n",
        "  print(\"Not Pangram\")"
      ],
      "metadata": {
        "id": "IHLmBhRH_bL8",
        "outputId": "fc74aca4-e7e8-4f60-8dbc-9a2801ab49ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not Pangram\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 3: Frequent patterns and association rules mining"
      ],
      "metadata": {
        "id": "QOoFk6Z2H13m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Load the data file: foodmart.csv\n",
        "\n",
        "\n",
        "*  A record is a tuple of binary values {0, 1}, each of which denotes the presence of an item (1: bought, 0: not bought).\n",
        "\n"
      ],
      "metadata": {
        "id": "uH3ozoTVH6J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nnthaofit/CSC14118.git\n",
        "df = spark.read.csv(\"CSC14118/foodmart.csv\", header=True, inferSchema = True)\n",
        "df.show()"
      ],
      "metadata": {
        "id": "4N9eo13QH_Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Convert the given data to the format required by Spark MLlib FPGrowth."
      ],
      "metadata": {
        "id": "FhDrkKXZH_dA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SryD0vQOuek5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.\tApply Spark MLlib FPGrowth to the formatted data. Mine the set of frequent patterns with the minimum support of 0.1. Mine the set of association rules with the minimum confidence of 0.9."
      ],
      "metadata": {
        "id": "OgVP1hS6IDVA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BaAIAGDeugcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 4: Classification"
      ],
      "metadata": {
        "id": "pxSuXFXoIHO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###0. Load the data file: mushroom.csv\n",
        "*   The data represents a collection of mushroom species.\n",
        "*   There are 8124 examples, each of which has 22 attributes and it is categorized into either “edible” (e) or “poisonous” (p)\n"
      ],
      "metadata": {
        "id": "mCMfeBzgIL0p"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SXGKh8EPIUJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.\tPrepare the train and test sets following the ratio 8:2"
      ],
      "metadata": {
        "id": "JdIdZJ2zIUge"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kAcyo8DJIZou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Fit a decision tree model on the training set, using Spark MLlib DecisionTreeClassifier with default parameters"
      ],
      "metadata": {
        "id": "zbshjQjnIZz8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TNbvDsqIIbNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Fit a random forest model on the training set, using Spark MLlib RandomForestClassification with default parameters"
      ],
      "metadata": {
        "id": "ghWaZW7LIbr-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jVhzgPw7IcOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Evaluate the two models on the same test set using the following metrics: areaUnderROC and areaUnderPR"
      ],
      "metadata": {
        "id": "TCWbqsk0IoSe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G4YrCL5-IohK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Chain the above steps into a single pipeline"
      ],
      "metadata": {
        "id": "cTJAVAGeIr3a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I3wOtZdWIzsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 5: Clustering"
      ],
      "metadata": {
        "id": "dn-fgVNlIxZN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nqGZvNcWIxih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.\tCluster the data by using Spark MLlib KMeans with k = 2, 3, and 5, using Euclidean distance and cosine distance"
      ],
      "metadata": {
        "id": "IdHBhBHqIxqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DJV4mX3_IxyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Evaluate each of the above clustering results using silhoutte score. Which configuration yeilds the best clustering?"
      ],
      "metadata": {
        "id": "dBo8pvyOIx5p"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3NekP_ioIyCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Chain the above steps into a single pipeline"
      ],
      "metadata": {
        "id": "GMAMYR1mJDk8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "429A9QeCIsT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. For each clustering result obtained above, count the number of examples that belong to each of the three species."
      ],
      "metadata": {
        "id": "h1ByWgvaJHp-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AYyWW4ltJII8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 6: Network manipulation with Spark GraphFrames"
      ],
      "metadata": {
        "id": "T5epMoIlJOr1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###0. Load the data files: users.txt and followers.txt"
      ],
      "metadata": {
        "id": "I1pTLkFgJUmB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q1WSkukOJT2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.\tConstruct a graph from the given data to demonstrate a tiny social network\n"
      ],
      "metadata": {
        "id": "zd6XAz-aJYlj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y7lOQereJONE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.\tApply Graphs graphPageRank to the network to obtain a ranking list of users in terms of followers"
      ],
      "metadata": {
        "id": "hSV29hkuJct7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SNAmL2y3Jc3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Find connected components on the graph, using Graphs connectedComponents or stronglyConnectedComponents"
      ],
      "metadata": {
        "id": "nIciqOCqJeqH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TqThg_PxJe0v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}